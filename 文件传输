"""
OAK-D 图片测试工具
方法：在屏幕上全屏显示测试图片，用 OAK-D 拍摄屏幕进行检测
"""

import cv2
import depthai as dai
import numpy as np
import time
from pathlib import Path
from collections import Counter
import subprocess
import os

# --- 配置 ---
MODEL_PATH = 'models/knottedblob/best10301nohue_openvino_2022.1_6shave.blob'
LABEL_MAP = ['Green', 'Red', 'Yellow']
NN_INPUT_SIZE = 416

# 测试图片配置
TEST_IMAGES_PATH = 'test_images_for_raspberry'  # 图片文件夹或 7z 文件
SAVE_RESULTS = True
RESULTS_DIR = 'test_results'

# 检测阈值
CLASS_THRESHOLDS = {
    'Green': 0.55,
    'Red': 0.50,
    'Yellow': 0.45
}

# 时序平滑
USE_SMOOTHING = True
BUFFER_SIZE = 5
MIN_VOTES = 3

# 显示模式
FULLSCREEN = True  # 全屏显示测试图片
AUTO_DETECT_TIMEOUT = 3.0  # 检测超时（秒）


# --- 辅助函数 ---
def extract_7z(archive_path):
    """解压 7z 文件"""
    try:
        import py7zr
        output_dir = archive_path.parent / (archive_path.stem + '_extracted')
        output_dir.mkdir(exist_ok=True)
        
        print(f"解压 7z: {archive_path}")
        with py7zr.SevenZipFile(archive_path, mode='r') as archive:
            archive.extractall(path=output_dir)
        
        print(f"✓ 解压完成: {output_dir}")
        return output_dir
    except ImportError:
        print("需要安装: pip install py7zr")
        return None
    except Exception as e:
        print(f"解压失败: {e}")
        return None


def find_images(path):
    """查找所有图片"""
    path = Path(path)
    
    # 处理 7z
    if path.suffix == '.7z':
        extract_dir = path.parent / (path.stem + '_extracted')
        if extract_dir.exists():
            path = extract_dir
        else:
            path = extract_7z(path)
            if path is None:
                return []
    
    # 查找图片
    if path.is_dir():
        extensions = ['.jpg', '.jpeg', '.png', '.bmp']
        images = []
        for ext in extensions:
            images.extend(path.rglob(f'*{ext}'))
            images.extend(path.rglob(f'*{ext.upper()}'))
        return sorted(images)
    
    return [path] if path.is_file() else []


def load_label(image_path):
    """加载对应的标签文件"""
    # 尝试多个可能的标签路径
    possible_paths = [
        image_path.parent / 'labels' / (image_path.stem + '.txt'),
        image_path.parent / (image_path.stem + '.txt'),
        image_path.parent.parent / 'labels' / (image_path.stem + '.txt')
    ]
    
    for label_path in possible_paths:
        if label_path.exists():
            try:
                with open(label_path, 'r') as f:
                    lines = f.readlines()
                
                labels = []
                for line in lines:
                    parts = line.strip().split()
                    if len(parts) >= 5:
                        class_id = int(parts[0])
                        bbox = list(map(float, parts[1:5]))
                        labels.append({
                            'class': LABEL_MAP[class_id] if class_id < len(LABEL_MAP) else 'unknown',
                            'bbox': bbox
                        })
                return labels
            except:
                pass
    
    return None


class TemporalSmoother:
    """时序平滑器"""
    def __init__(self, buffer_size=5, min_votes=3):
        self.buffer_size = buffer_size
        self.min_votes = min_votes
        self.buffer = []
    
    def add(self, detection):
        self.buffer.append(detection)
        if len(self.buffer) > self.buffer_size:
            self.buffer.pop(0)
    
    def get_result(self):
        if len(self.buffer) < self.min_votes:
            return None
        
        # 投票
        valid_labels = [d['label'] for d in self.buffer if d is not None]
        if len(valid_labels) < self.min_votes:
            return None
        
        label_counts = Counter(valid_labels)
        most_common, votes = label_counts.most_common(1)[0]
        
        if votes < self.min_votes:
            return None
        
        # 平均置信度
        confs = [d['confidence'] for d in self.buffer if d and d['label'] == most_common]
        avg_conf = np.mean(confs) if confs else 0
        
        return {
            'label': most_common,
            'confidence': avg_conf,
            'votes': f"{votes}/{len(self.buffer)}"
        }
    
    def reset(self):
        self.buffer.clear()


# --- 主程序 ---
print("=" * 70)
print("OAK-D 图片批量测试工具")
print("=" * 70)

# 查找图片
images = find_images(TEST_IMAGES_PATH)

if not images:
    print(f"❌ 未找到图片: {TEST_IMAGES_PATH}")
    exit(1)

print(f"\n找到 {len(images)} 张图片")
print(f"模型: {MODEL_PATH}")
print(f"阈值: {CLASS_THRESHOLDS}")
print("=" * 70)

# 创建结果目录
if SAVE_RESULTS:
    results_dir = Path(RESULTS_DIR)
    results_dir.mkdir(exist_ok=True)

# 构建 Pipeline
print("\n构建 Pipeline...")
pipeline = dai.Pipeline()

cam_rgb = pipeline.create(dai.node.ColorCamera)
monoLeft = pipeline.create(dai.node.MonoCamera)
monoRight = pipeline.create(dai.node.MonoCamera)
stereo = pipeline.create(dai.node.StereoDepth)
spatial_nn = pipeline.create(dai.node.YoloSpatialDetectionNetwork)

xout_rgb = pipeline.create(dai.node.XLinkOut)
xout_rgb.setStreamName("rgb")
xout_nn = pipeline.create(dai.node.XLinkOut)
xout_nn.setStreamName("detections")

cam_rgb.setPreviewSize(NN_INPUT_SIZE, NN_INPUT_SIZE)
cam_rgb.setResolution(dai.ColorCameraProperties.SensorResolution.THE_1080_P)
cam_rgb.setInterleaved(False)
cam_rgb.setColorOrder(dai.ColorCameraProperties.ColorOrder.BGR)

monoLeft.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)
monoLeft.setBoardSocket(dai.CameraBoardSocket.LEFT)
monoRight.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)
monoRight.setBoardSocket(dai.CameraBoardSocket.RIGHT)

stereo.setDefaultProfilePreset(dai.node.StereoDepth.PresetMode.HIGH_DENSITY)
stereo.setDepthAlign(dai.CameraBoardSocket.RGB)

spatial_nn.setBlobPath(MODEL_PATH)
spatial_nn.setConfidenceThreshold(0.3)
spatial_nn.input.setBlocking(False)
spatial_nn.setBoundingBoxScaleFactor(0.5)
spatial_nn.setDepthLowerThreshold(100)
spatial_nn.setDepthUpperThreshold(10000)

spatial_nn.setNumClasses(len(LABEL_MAP))
spatial_nn.setCoordinateSize(4)
spatial_nn.setAnchors([10, 13, 16, 30, 33, 23, 30, 61, 62, 45, 59, 119, 116, 90, 156, 198, 373, 326])
spatial_nn.setAnchorMasks({"side52": [0, 1, 2], "side26": [3, 4, 5], "side13": [6, 7, 8]})
spatial_nn.setIouThreshold(0.5)

monoLeft.out.link(stereo.left)
monoRight.out.link(stereo.right)
cam_rgb.preview.link(spatial_nn.input)
stereo.depth.link(spatial_nn.inputDepth)

spatial_nn.passthrough.link(xout_rgb.input)
spatial_nn.out.link(xout_nn.input)

print("\n按键说明:")
print("  SPACE  - 下一张")
print("  b      - 上一张")
print("  c      - 开始检测当前图片")
print("  s      - 保存结果")
print("  q      - 退出")
print("  1-6    - 调整阈值")
print("=" * 70)

# --- 测试循环 ---
try:
    with dai.Device(pipeline) as device:
        print("\n✓ 设备连接成功\n")
        
        q_rgb = device.getOutputQueue("rgb", 4, False)
        q_nn = device.getOutputQueue("detections", 4, False)
        
        smoother = TemporalSmoother(BUFFER_SIZE, MIN_VOTES)
        
        # 统计
        results_log = []
        
        idx = 0
        detecting = False
        detect_start_time = 0
        
        # 创建显示窗口
        cv2.namedWindow("Test Image", cv2.WINDOW_NORMAL)
        if FULLSCREEN:
            cv2.setWindowProperty("Test Image", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)
        
        cv2.namedWindow("OAK-D View", cv2.WINDOW_NORMAL)
        
        while idx < len(images):
            img_path = images[idx]
            
            # 读取测试图片
            test_img = cv2.imread(str(img_path))
            if test_img is None:
                print(f"❌ 无法读取: {img_path}")
                idx += 1
                continue
            
            # 加载标签
            gt_labels = load_label(img_path)
            
            # 显示测试图片（在屏幕上全屏显示，让 OAK-D 拍摄）
            display_img = test_img.copy()
            
            # 添加信息
            info = f"[{idx+1}/{len(images)}] {img_path.name}"
            cv2.putText(display_img, info, (20, 40),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            
            if gt_labels:
                gt_text = "GT: " + ", ".join([l['class'] for l in gt_labels])
                cv2.putText(display_img, gt_text, (20, 80),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            
            status = "检测中..." if detecting else "按 C 开始检测"
            cv2.putText(display_img, status, (20, 120),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255) if detecting else (255, 255, 255), 2)
            
            cv2.imshow("Test Image", display_img)
            
            # 获取 OAK-D 视图
            in_rgb = q_rgb.get()
            in_nn = q_nn.get()
            
            oak_frame = in_rgb.getCvFrame()
            detections = in_nn.detections
            
            # 过滤检测
            filtered = []
            for det in detections:
                try:
                    label = LABEL_MAP[det.label]
                    if det.confidence >= CLASS_THRESHOLDS[label]:
                        filtered.append({
                            'label': label,
                            'confidence': det.confidence,
                            'bbox': [det.xmin, det.ymin, det.xmax, det.ymax]
                        })
                except:
                    pass
            
            # 显示 OAK-D 视图
            oak_display = oak_frame.copy()
            
            # 如果正在检测
            if detecting:
                if filtered:
                    smoother.add(filtered[0] if filtered else None)
                
                # 检测超时
                if time.time() - detect_start_time > AUTO_DETECT_TIMEOUT:
                    result = smoother.get_result()
                    
                    if result:
                        print(f"\n[{idx+1}] 检测结果: {result['label']} ({result['confidence']:.2f}) {result['votes']}")
                    else:
                        print(f"\n[{idx+1}] 无检测结果")
                    
                    if gt_labels:
                        gt_str = ", ".join([l['class'] for l in gt_labels])
                        print(f"     真实标签: {gt_str}")
                    
                    results_log.append({
                        'image': img_path.name,
                        'predicted': result['label'] if result else None,
                        'ground_truth': gt_labels
                    })
                    
                    detecting = False
                    smoother.reset()
            
            # 绘制检测框
            for det in filtered:
                x1 = int(det['bbox'][0] * oak_frame.shape[1])
                y1 = int(det['bbox'][1] * oak_frame.shape[0])
                x2 = int(det['bbox'][2] * oak_frame.shape[1])
                y2 = int(det['bbox'][3] * oak_frame.shape[0])
                
                label = det['label']
                color = (0, 255, 0) if label == 'Green' else (0, 0, 255) if label == 'Red' else (0, 255, 255)
                
                cv2.rectangle(oak_display, (x1, y1), (x2, y2), color, 2)
                cv2.putText(oak_display, f"{label} {det['confidence']:.2f}",
                           (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
            
            cv2.imshow("OAK-D View", oak_display)
            
            # 键盘控制
            key = cv2.waitKey(50)
            
            if key == ord('q'):
                break
            elif key == ord(' '):
                idx += 1
                detecting = False
                smoother.reset()
            elif key == ord('b'):
                idx = max(0, idx - 1)
                detecting = False
                smoother.reset()
            elif key == ord('c'):
                if not detecting:
                    print(f"\n开始检测: {img_path.name}")
                    detecting = True
                    detect_start_time = time.time()
                    smoother.reset()
            elif key == ord('s'):
                if SAVE_RESULTS:
                    result_path = results_dir / f"result_{img_path.name}"
                    cv2.imwrite(str(result_path), oak_display)
                    print(f"✓ 已保存: {result_path}")
            elif key >= ord('1') and key <= ord('6'):
                # 阈值调整（同之前）
                pass
        
        # 显示统计
        print("\n" + "=" * 70)
        print("测试完成")
        print("=" * 70)
        print(f"测试图片数: {len(results_log)}")
        
        # 保存日志
        if results_log:
            log_path = results_dir / 'test_log.txt'
            with open(log_path, 'w') as f:
                for r in results_log:
                    f.write(f"{r}\n")
            print(f"日志已保存: {log_path}")
        
        print("=" * 70)

except Exception as e:
    print(f"\n❌ 错误: {e}")
    import traceback
    traceback.print_exc()

finally:
    cv2.destroyAllWindows()
    print("\n✓ 测试结束")
