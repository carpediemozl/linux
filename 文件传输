"""
视频红绿灯检测工具
只检测视频文件中的红绿灯，移除了OAK-D相关代码
"""

import cv2
import depthai as dai
import numpy as np
import time
from pathlib import Path
from collections import deque, Counter
import sys

# --- 配置 ---
MODEL_PATH = 'models/knottedblob/best10301nohue_openvino_2022.1_6shave.blob'
LABEL_MAP = ['Green', 'Red', 'Yellow']
NN_INPUT_SIZE = 416

# 检测阈值
CLASS_THRESHOLDS = {
    'Green': 0.55,
    'Red': 0.50,
    'Yellow': 0.45
}

def create_pipeline():
    """创建推理pipeline"""
    pipeline = dai.Pipeline()
    
    # 神经网络节点
    nn = pipeline.create(dai.node.NeuralNetwork)
    nn.setBlobPath(MODEL_PATH)
    nn.setNumInferenceThreads(2)
    nn.input.setBlocking(False)
    
    # 输入输出节点
    xin = pipeline.create(dai.node.XLinkIn)
    xin.setStreamName("in")
    xout = pipeline.create(dai.node.XLinkOut)
    xout.setStreamName("out")
    
    xin.out.link(nn.input)
    nn.out.link(xout.input)
    
    return pipeline

def process_frame(frame, size=None):
    """预处理帧"""
    if size:
        frame = cv2.resize(frame, (size, size))
    return frame

def main(video_path):
    print(f"开始处理视频: {video_path}")
    
    # 打开视频文件
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"无法打开视频: {video_path}")
        return
    
    # 获取视频信息
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    print(f"视频信息: {frame_width}x{frame_height} @ {fps}fps")
    
    # 创建pipeline
    pipeline = create_pipeline()
    
    try:
        with dai.Device(pipeline) as device:
            print("设备已连接")
            
            # 获取输入输出队列
            q_in = device.getInputQueue(name="in")
            q_out = device.getOutputQueue(name="out")
            
            frame_count = 0
            start_time = time.time()
            
            cv2.namedWindow("Detection", cv2.WINDOW_NORMAL)
            
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break
                
                frame_count += 1
                
                # 预处理
                processed = process_frame(frame, NN_INPUT_SIZE)
                
                # 准备输入
                img = dai.ImgFrame()
                img.setData(processed.transpose(2, 0, 1).flatten())
                img.setWidth(NN_INPUT_SIZE)
                img.setHeight(NN_INPUT_SIZE)
                img.setType(dai.ImgFrame.Type.BGR888p)
                
                # 发送到设备
                q_in.send(img)
                
                # 获取结果
                result = q_out.get()
                
                # 处理检测结果
                detections = np.array(result.getFirstLayerFp16()).reshape((-1, 7))
                
                # 显示结果
                display = frame.copy()
                
                for detection in detections:
                    if detection[2] > CLASS_THRESHOLDS[LABEL_MAP[int(detection[1])]]:
                        label = LABEL_MAP[int(detection[1])]
                        confidence = detection[2]
                        
                        # 转换坐标
                        x1 = int(detection[3] * frame_width)
                        y1 = int(detection[4] * frame_height)
                        x2 = int(detection[5] * frame_width)
                        y2 = int(detection[6] * frame_height)
                        
                        # 绘制检测框
                        color = (0,255,0) if label == 'Green' else (0,0,255) if label == 'Red' else (0,255,255)
                        cv2.rectangle(display, (x1, y1), (x2, y2), color, 2)
                        cv2.putText(display, f"{label} {confidence:.2f}", 
                                  (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
                
                # 显示进度
                progress = frame_count / total_frames * 100
                fps = frame_count / (time.time() - start_time)
                cv2.putText(display, f"Progress: {progress:.1f}% FPS: {fps:.1f}", 
                          (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
                
                cv2.imshow("Detection", display)
                
                key = cv2.waitKey(1)
                if key == ord('q'):
                    break
                elif key == ord('s'):
                    cv2.imwrite(f"frame_{frame_count:06d}.jpg", display)
                    print(f"已保存帧: frame_{frame_count:06d}.jpg")
    
    except Exception as e:
        print(f"错误: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        cap.release()
        cv2.destroyAllWindows()
        print("处理完成")

if __name__ == '__main__':
    if len(sys.argv) != 2:
        print("使用方法: python script.py <video_path>")
        sys.exit(1)
    
    video_path = sys.argv[1]
    main(video_path)
